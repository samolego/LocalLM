# LocalLM

Android app to run LLMs on-device using llama.cpp

## Please note

This project is under development as part of my bachelor thesis.
Currently, some paths are hardcoded so this won't work for you.
